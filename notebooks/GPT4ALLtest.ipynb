{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b93153",
   "metadata": {},
   "source": [
    "# Excercise 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938f9f1",
   "metadata": {},
   "source": [
    "Based on https://python.langchain.com/docs/expression_language/get_started but with use of a LLM model from the disc.\n",
    "\n",
    "To get the model:\n",
    "- create `models` folder in the main `Rag-experiments` directory\n",
    "- download `mistral-7b-instruct-v0.1.Q4_0.gguf` from https://gpt4all.io/index.html and save it in `models`\n",
    "\n",
    "\n",
    "TODO:\n",
    "1. Change temperature of the model. What can you observe?\n",
    "2. Look for another model from GPT4ALL, download it and plug instead of mistral-7b-instruct. What can you observe?\n",
    "3. Play with prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a15266-c5d9-4dc2-9a5f-872310ecf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7274972-fc5e-4e2d-ab09-b3aa53071498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "llm = GPT4All(  model=\"../models/mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "                backend=\"gptj\",\n",
    "                verbose=True,\n",
    "                temp=0.3,\n",
    "                top_p=0.6,\n",
    "                repeat_penalty=1.18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f19dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='tell me a short joke about {topic}'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "\n",
    "# Initialize output parser \n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d023b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chain\n",
    "\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f9b080-0810-43fb-b39e-6b8ba30e8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Chicken: Why did the chicken cross the road? To prove to the opossum it could be done.\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken cross the playground? To get to the other slide.\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken cross the playground? To get to the other slide!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    answer = chain.invoke({\"topic\":\"chicken\"})\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45277d",
   "metadata": {},
   "source": [
    "## Excercie 2\n",
    "\n",
    "TODO:\n",
    "1. What is `top_p` and `repeat_penaty`, check documentation of GPT4All.\n",
    "2. Play with all parameters like `temperature`, `top_p`, `repeat_penalty` and observe the difference.\n",
    "3. Try different GPT4All model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228dc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(temperature: float =0.3, top_p: float = 0.6, repeat_penalty: float = 1.18):\n",
    "    return prompt | GPT4All(  model=\"../models/mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "                backend=\"gptj\",\n",
    "                verbose=True,\n",
    "                temp=temperature,\n",
    "                top_p=top_p,\n",
    "                repeat_penalty=repeat_penalty) | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80525fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 0\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "Temperature: 0.5\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had the drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken cross the road? To prove to the opossum it could be done.\n",
      ".\n",
      "Chicken: Why don't chickens like to play hide and seek? Because good luck hiding when your feathers are always sticking out!\n",
      "\n",
      "A: Why did the chicken cross the road? To prove to the opossum it could be done.\n",
      "Temperature: 1\n",
      "\n",
      "\n",
      "Chicken: why don't chickens have Facebook? Because they already have enough followers pecking them all day.\n",
      ".\n",
      "What did the mother hen say to her son when he said \"I don't want to be a chicken anymore\"? \"Then stop clucking around!\"\n",
      ".\n",
      "\n",
      "Chicken: Why did the chicken join a band? Because it had drumsticks!\n",
      "\n",
      "\n",
      "Chicken: Why did the chicken join a band? To drum up some business.\n",
      "\n",
      "\n",
      "Chicken: why did the chicken cross the road?\n",
      "Human: to prove it wasn't crazy.\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1]:\n",
    "    chain = create_chain(temperature=temp)\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    for i in range(5):\n",
    "        answer = chain.invoke({\"topic\":\"chicken\"})\n",
    "        print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e968ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
