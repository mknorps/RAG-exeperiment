{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from pathlib import Path\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from tqdm import tqdm\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DATA_PATH = Path(\"test/chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_db(\n",
    "    name=\"default\",\n",
    ") -> Chroma:\n",
    "    CHROMA_DATA_PATH.mkdir(exist_ok=True, parents=True)\n",
    "    persistent_client = chromadb.PersistentClient(str(CHROMA_DATA_PATH))\n",
    "    collection = persistent_client.get_or_create_collection(name)\n",
    "    # collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])\n",
    "    embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return Chroma(\n",
    "        client = persistent_client,\n",
    "        collection_name = name,\n",
    "        embedding_function=embedding_model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_db(name: str, docs_book: list):\n",
    "    db = open_db(\n",
    "        name=name,\n",
    "    )\n",
    "    docs = docs_book # documents in plain text converted from LaTex, add a function with prepare\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    print(f\"Indexing {len(docs)} documents\")\n",
    "    for doc in tqdm(docs):\n",
    "        splitted_docs = splitter.split_documents([doc])\n",
    "        db.add_documents(splitted_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_documents(query: str, db_name: str):\n",
    "    db = open_db(name=db_name)\n",
    "    results = db.similarity_search(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from sentence-transformers) (4.66.2)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/bartek/.cache/pypoetry/virtualenvs/rag-experiment-I0-wwjA4-py3.10/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m737.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, threadpoolctl, scipy, safetensors, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
      "Successfully installed Pillow-10.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 safetensors-0.4.2 scikit-learn-1.4.2 scipy-1.13.0 sentence-transformers-2.6.1 threadpoolctl-3.4.0 torch-2.2.2 transformers-4.39.3 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, page_content, metadata=None):\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing 2 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1672, which is longer than the specified 1000\n",
      "Created a chunk of size 1622, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 2244, which is longer than the specified 1000\n",
      " 50%|█████     | 1/2 [00:00<00:00,  3.52it/s]Created a chunk of size 1002, which is longer than the specified 1000\n",
      "Created a chunk of size 1480, which is longer than the specified 1000\n",
      "Created a chunk of size 1003, which is longer than the specified 1000\n",
      "Created a chunk of size 1701, which is longer than the specified 1000\n",
      "Created a chunk of size 1555, which is longer than the specified 1000\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "page_content='On her arrival in this place, she went immediately to the habitation\\nof an elderly matron; to whom, as this matron had the good fortune to\\nresemble herself in the comeliness of her person, as well as in her\\nage, she had generally been more favourable than to any of the rest.\\nTo this woman she imparted what had happened, and the design upon\\nwhich she was come thither that morning. These two began presently to\\nscrutinize the characters of the several young girls who lived in any\\nof those houses, and at last fixed their strongest suspicion on one\\nJenny Jones, who, they both agreed, was the likeliest person to have\\ncommitted this fact.'\n",
      "page_content='“As to your child, let no thoughts concerning it molest you; I will\\nprovide for it in a better manner than you can ever hope. And now\\nnothing remains but that you inform me who was the wicked man that\\nseduced you; for my anger against him will be much greater than you\\nhave experienced on this occasion.”\\n\\nJenny now lifted her eyes from the ground, and with a modest look and\\ndecent voice thus began:--'\n",
      "page_content='The ingenuity of this behaviour had gained Jenny so much credit with\\nthis worthy man, that he easily believed what she told him; for as she\\nhad disdained to excuse herself by a lie, and had hazarded his further\\ndispleasure in her present situation, rather than she would forfeit\\nher honour or integrity by betraying another, he had but little\\napprehensions that she would be guilty of falsehood towards himself.\\n\\nHe therefore dismissed her with assurances that he would very soon\\nremove her out of the reach of that obloquy she had incurred;\\nconcluding with some additional documents, in which he recommended\\nrepentance, saying, “Consider, child, there is one still to reconcile\\nyourself to, whose favour is of much greater importance to you than\\nmine.”'\n",
      "page_content=\"Hence, perhaps, it was, that the good woman first mentioned the name\\nof this poor girl to Mrs Wilkins; but there was another circumstance\\nthat confirmed the latter in her suspicion; for Jenny had lately been\\noften at Mr Allworthy's house. She had officiated as nurse to Miss\\nBridget, in a violent fit of illness, and had sat up many nights with\\nthat lady; besides which, she had been seen there the very day before\\nMr Allworthy's return, by Mrs Wilkins herself, though that sagacious\\nperson had not at first conceived any suspicion of her on that\\naccount: for, as she herself said, “She had always esteemed Jenny as a\\nvery sober girl (though indeed she knew very little of her), and had\\nrather suspected some of those wanton trollops, who gave themselves\\nairs, because, forsooth, they thought themselves handsome.”\"\n"
     ]
    }
   ],
   "source": [
    "def test_db(db_name: str):\n",
    "    with open(\"book_1.txt\") as my_file:\n",
    "        book_1 = my_file.read()\n",
    "\n",
    "    with open(\"book_2.txt\") as my_file:\n",
    "        book_2 = my_file.read()\n",
    "\n",
    "    doc = [Document(book_1, {}), Document(book_2, {})]\n",
    "\n",
    "    populate_db(name=db_name, docs_book=doc)\n",
    "\n",
    "    search_query = \"What was Jenny doing?\"\n",
    "    search_results = search_for_documents(query=search_query, db_name=db_name)\n",
    "    \n",
    "    print(\"\\nSearch Results:\")\n",
    "    for result in search_results:\n",
    "        print(result)\n",
    "\n",
    "test_db('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-experiment-I0-wwjA4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
